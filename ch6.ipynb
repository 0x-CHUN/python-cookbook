{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Êï∞ÊçÆÁºñÁ†ÅÂíåÂ§ÑÁêÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËØªÂÜôcsvÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "]\n",
    "\n",
    "with open('data/stocks.csv','w', newline='') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "{'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "{'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "]\n",
    "with open('data/stocks.csv','w', newline='') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n"
    }
   ],
   "source": [
    "import csv\n",
    "with open('data/stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    header = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AA 39.48\nAIG 71.38\nAXP 62.58\n"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "with open('data/stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    header = next(f_csv)\n",
    "    Row = namedtuple('Row', header)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        print(row.Symbol, row.Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AA 39.48\nAIG 71.38\nAXP 62.58\n"
    }
   ],
   "source": [
    "with open('data/stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row['Symbol'], row['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËØªÂÜôJSONÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'{\"name\": \"ACME\", \"share\": 100, \"price\": 542.23}'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name' : 'ACME',\n",
    "    'share' : 100,\n",
    "    'price' : 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'ACME', 'share': 100, 'price': 542.23}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data = json.loads(json_str)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'chun', 'share': 100, 'price': 542.23}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data['name'] = 'chun'\n",
    "with open('data/data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "with open('data/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ëß£ÊûêÁÆÄÂçïÁöÑXMLÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PSF GSoC students blogs: Weekly Check In - 6\nWed, 15 Jul 2020 20:04:20 +0000\nhttps://blogs.python-gsoc.org/en/adityaa30s-blog/weekly-check-in-6-12/\n\nIan Ozsvald: Weekish notes\nWed, 15 Jul 2020 19:20:59 +0000\nhttps://ianozsvald.com/2020/07/15/weekish-notes-2/\n\nJanusworx: A Hundred Days of Code, Day 008 - Python Basics, Lists, Tuples, Dictionaries, Sets and Done!\nWed, 15 Jul 2020 14:02:58 +0000\nhttps://janusworx.com/blog/a-hundred-days-of-code-day-008-python-basics-lists-tuples-dictionaries-sets-and-done/\n\nReal Python: Pandas Project: Make a Gradebook With Python &amp; Pandas\nWed, 15 Jul 2020 14:00:00 +0000\nhttps://realpython.com/pandas-project-gradebook/\n\nCatalin George Festila: Python 3.8.3 : Lists in Python 3 - part 001.\nWed, 15 Jul 2020 13:23:18 +0000\nhttp://python-catalin.blogspot.com/2020/07/python-383-lists-in-python-3-part-001.html\n\nAndriy Kornatskyy: Python Templates Benchmark\nWed, 15 Jul 2020 10:37:08 +0000\nhttp://mindref.blogspot.com/2012/10/python-templates-benchmark.html\n\nAndriy Kornatskyy: Python Fastest Template Engine\nWed, 15 Jul 2020 10:37:08 +0000\nhttp://mindref.blogspot.com/2012/07/python-fastest-template.html\n\nCodementor: How should I start learning Python\nWed, 15 Jul 2020 06:55:22 +0000\nhttps://www.codementor.io/narendranareshit/how-should-i-start-learning-python-18dmbgg5pu\n\nMike Driscoll: Python 101 ‚Äì Creating Multiple Processes\nWed, 15 Jul 2020 05:05:17 +0000\nhttps://www.blog.pythonlibrary.org/2020/07/15/python-101-creating-multiple-processes/\n\nAnarcat: Goatcounter analytics in ikiwiki\nWed, 15 Jul 2020 02:07:52 +0000\nhttps://anarc.at/services/analytics/\n\nPSF GSoC students blogs: Week 6 Check-in\nWed, 15 Jul 2020 00:54:56 +0000\nhttps://blogs.python-gsoc.org/en/joaosferreiras-blog/week-6-check-in-2/\n\nPSF GSoC students blogs: Week 7 check-in!\nTue, 14 Jul 2020 23:57:28 +0000\nhttps://blogs.python-gsoc.org/en/imaj_ashwinis-blog/week-7-check-in-1/\n\nCodementor: Your First Stock Trading Bot ü§ñüêçPart 2: Buy &amp; Sell Stocks in Python w/ Alpaca!\nTue, 14 Jul 2020 23:09:53 +0000\nhttps://www.codementor.io/powderblock/your-first-stock-trading-bot-part-2-buy-sell-stocks-in-python-w-alpaca-15i9btwqyi\n\nNumFOCUS: Open Source Developer Advocate\nTue, 14 Jul 2020 20:36:34 +0000\nhttps://numfocus.org/jobs/open-source-developer-advocate?utm_source=rss&utm_medium=rss&utm_campaign=open-source-developer-advocate\n\nPyCoder‚Äôs Weekly: Issue #429 (July 14, 2020)\nTue, 14 Jul 2020 19:30:00 +0000\nhttps://pycoders.com/issues/429\n\nEuroPython: EuroPython 2020: Please configure your tickets\nTue, 14 Jul 2020 16:58:06 +0000\nhttps://blog.europython.eu/post/623636263112720384\n\nReal Python: Grow Your Python Portfolio With 13 Intermediate Project Ideas\nTue, 14 Jul 2020 14:00:00 +0000\nhttps://realpython.com/courses/intermediate-project-ideas/\n\nJanusworx: A Hundred Days of Code, Day 007 - Python Basics, Variables, Basic Data Types, Strings and Loops\nTue, 14 Jul 2020 12:56:08 +0000\nhttps://janusworx.com/blog/a-hundred-days-of-code-day-007-python-basics-variables-basic-data-types-strings-and-loops/\n\nKushal Das: Introducing pyage-rust, a Python module for age encryption\nTue, 14 Jul 2020 10:09:56 +0000\nhttps://kushaldas.in/posts/introducing-pyage-rust-a-python-module-for-age-encryption.html\n\nPSF GSoC students blogs: Check-in for week 6\nTue, 14 Jul 2020 07:38:25 +0000\nhttps://blogs.python-gsoc.org/en/lukas0907s-blog/check-in-for-week-6/\n\nMike Driscoll: An Overview of JupyterLab (Video)\nTue, 14 Jul 2020 05:05:15 +0000\nhttps://www.blog.pythonlibrary.org/2020/07/14/an-overview-of-jupyterlab-video/\n\nAnarcat: Not recommending Purism\nMon, 13 Jul 2020 22:15:59 +0000\nhttps://anarc.at/blog/2020-07-13-not-recommending-purism/\n\nPSF GSoC students blogs: Weekly Check-In | Gsoc'2020 | #7\nMon, 13 Jul 2020 21:48:59 +0000\nhttps://blogs.python-gsoc.org/en/shashankjarials-blog/weekly-check-in-gsoc-2020-7/\n\nPSF GSoC students blogs: Weekly Check-in #7\nMon, 13 Jul 2020 18:33:36 +0000\nhttps://blogs.python-gsoc.org/en/aghinsas-blog/weekly-check-in-7-6/\n\nPython Software Foundation: Pip team midyear report\nMon, 13 Jul 2020 18:23:13 +0000\nhttp://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/ajy0RSDt9zE/pip-team-midyear-report.html\n\n"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â¢ûÈáèÂºèËß£ÊûêÂ§ßÂûãXMLÊñá‰ª∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    next(doc)\n",
    "\n",
    "    tag_stacks = []\n",
    "    elem_stacks = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stacks.append(elem.tag)\n",
    "            elem_stacks.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stacks == path_parts:\n",
    "                yield elem\n",
    "                elem_stacks[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stacks.pop()\n",
    "                elem_stacks.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â∞ÜÂ≠óÂÖ∏ËΩ¨Êç¢‰∏∫XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'<stock><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem\n",
    "\n",
    "s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 }\n",
    "e = dict_to_xml('stock', s)\n",
    "from xml.etree.ElementTree import tostring\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'<stock id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "e.set('id', '1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ëß£ÊûêÂíå‰øÆÊîπXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "\n",
    "doc = parse('data/pred.xml')\n",
    "root = doc.getroot()\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))\n",
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)\n",
    "doc.write('data/newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‰∏éÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÁöÑ‰∫§‰∫í"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [\n",
    "    ('GOOG', 100, 490.1),\n",
    "    ('AAPL', 50, 545.75),\n",
    "    ('FB', 150, 7.45),\n",
    "    ('HPQ', 75, 33.2),\n",
    "]\n",
    "import sqlite3\n",
    "db = sqlite3.connect('data/database.db')\n",
    "c = db.cursor()\n",
    "c.execute('drop table if exists portfolio')\n",
    "c.execute('create table portfolio (symbol text, share integer, price real)')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.executemany('insert into portfolio values (?,?,?)',stocks)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('GOOG', 100, 490.1)\n('AAPL', 50, 545.75)\n('FB', 150, 7.45)\n('HPQ', 75, 33.2)\n"
    }
   ],
   "source": [
    "for row in db.execute('select * from portfolio'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('GOOG', 100, 490.1)\n('AAPL', 50, 545.75)\n"
    }
   ],
   "source": [
    "min_price = 100\n",
    "for row in db.execute('select * from portfolio where price >= ?', (min_price,)):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÁºñÁ†ÅÂíåËß£Á†ÅÂçÅÂÖ≠ËøõÂà∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'68656c6c6f'"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "s = b'hello'\n",
    "import binascii\n",
    "h = binascii.b2a_hex(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'hello'"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "binascii.a2b_hex(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'68656C6C6F'"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "import base64\n",
    "h = base64.b16encode(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'hello'"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "base64.b16decode(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÁºñÁ†ÅËß£Á†ÅBase64Êï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "b'aGVsbG8='\nb'hello'\n"
    }
   ],
   "source": [
    "s = b'hello'\n",
    "import base64\n",
    "a = base64.b64encode(s)\n",
    "print(a)\n",
    "print(base64.b64decode(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËØªÂÜô‰∫åËøõÂà∂Êï∞ÁªÑÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))\n",
    "\n",
    "records = [ \n",
    "    (1, 2.3, 4.5),\n",
    "    (6, 7.8, 9.0),\n",
    "    (12, 13.4, 56.7)\n",
    "    ]\n",
    "with open('data/data.b', 'wb') as f:\n",
    "    write_records(records, '<idd', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 2.3, 4.5)\n(6, 7.8, 9.0)\n(12, 13.4, 56.7)\n"
    }
   ],
   "source": [
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size),b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "with open('data/data.b', 'rb') as f:\n",
    "    for rec in read_records('<idd', f):\n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËØªÂèñÂµåÂ•óÂíåÂèØÂèòÈïø‰∫åËøõÂà∂Êï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = [\n",
    "    [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],\n",
    "    [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],\n",
    "    [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],\n",
    "]\n",
    "\n",
    "import struct\n",
    "import itertools\n",
    "\n",
    "def write_polys(filename, polys):\n",
    "    flattened = list(itertools.chain(*polys))\n",
    "    min_x = min(x for x, y in flattened)\n",
    "    min_y = min(y for x, y in flattened)\n",
    "    max_x = max(x for x, y in flattened)\n",
    "    max_y = max(y for x, y in flattened)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(struct.pack('<iddddi',0x1234,min_x,min_y,max_x,max_y,len(polys)))\n",
    "        for poly in polys:\n",
    "            size = len(poly) * struct.calcsize('<dd')\n",
    "            f.write(struct.pack('<i', size+4))\n",
    "            for pt in poly:\n",
    "                f.write(struct.pack('<dd', *pt))\n",
    "\n",
    "write_polys('data/poly.bin', polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[(1.0, 2.5), (3.5, 4.0), (2.5, 1.5)],\n [(7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0)],\n [(3.4, 6.3), (1.2, 0.5), (4.6, 9.2)]]"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "def read_polys(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        header = f.read(40)\n",
    "        file_code, min_x, min_y, max_x, max_y, num_polys = struct.unpack('<iddddi', header)\n",
    "        polys = []\n",
    "        for n in range(num_polys):\n",
    "            pbytes, = struct.unpack('<i', f.read(4))\n",
    "            poly = []\n",
    "            for m in range(pbytes // 16):\n",
    "                pt = struct.unpack('<dd', f.read(16))\n",
    "                poly.append(pt)\n",
    "            polys.append(poly)\n",
    "        return polys\n",
    "\n",
    "read_polys('data/poly.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n0.5\n0.5\n7.0\n9.2\n"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "class StructField:\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(self.format, instance._buffer, self.offset)\n",
    "            return r[0] if len(r) == 1 else r\n",
    "\n",
    "class Structure:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)\n",
    "\n",
    "class PolyHeader(Structure):\n",
    "    file_code = StructField('<i', 0)\n",
    "    min_x = StructField('<d', 4)\n",
    "    min_y = StructField('<d', 12)\n",
    "    max_x = StructField('<d', 20)\n",
    "    max_y = StructField('<d', 28)\n",
    "    num_polys = StructField('<i', 36)\n",
    "\n",
    "f = open('data/poly.bin', 'rb')\n",
    "phead = PolyHeader(f.read(40))\n",
    "print(phead.file_code == 0x1234)\n",
    "print(phead.min_x)\n",
    "print(phead.min_y)\n",
    "print(phead.max_x)\n",
    "print(phead.max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n0.5\n0.5\n7.0\n9.2\n"
    }
   ],
   "source": [
    "class StructureMeta(type):\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fileds = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fileds:\n",
    "            if format.startswith(('<','>','!','@')):\n",
    "                byte_order = format[0]\n",
    "                format = format[1:]\n",
    "            format = byte_order + format\n",
    "            setattr(self, fieldname, StructField(format, offset))\n",
    "            offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)\n",
    "\n",
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))\n",
    "\n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        ('d', 'min_x'),\n",
    "        ('d', 'min_y'),\n",
    "        ('d', 'max_x'),\n",
    "        ('d', 'max_y'),\n",
    "        ('i', 'num_polys')\n",
    "    ]\n",
    "\n",
    "f = open('data/poly.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "print(phead.file_code == 0x1234)\n",
    "print(phead.min_x)\n",
    "print(phead.min_y)\n",
    "print(phead.max_x)\n",
    "print(phead.max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n0.5\n0.5\n7.0\n9.2\n"
    }
   ],
   "source": [
    "class NestedStruct:\n",
    "    def __init__(self, name, struct_type, offset):\n",
    "        self.name = name\n",
    "        self.struct_type = struct_type\n",
    "        self.offset = offset\n",
    "        \n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            data = instance._buffer[self.offset:\n",
    "            self.offset+self.struct_type.struct_size]\n",
    "            result = self.struct_type(data)\n",
    "            setattr(instance, self.name, result)\n",
    "            return result\n",
    "\n",
    "class StructureMeta(type):\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fileds = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fileds:\n",
    "            if isinstance(format, StructureMeta):\n",
    "                setattr(self, fieldname, NestedStruct(fieldname, format, offset))\n",
    "                offset += format.struct_size\n",
    "            else:\n",
    "                if format.startswith(('<','>','!','@')):\n",
    "                    byte_order = format[0]\n",
    "                    format = format[1:]\n",
    "                format = byte_order + format\n",
    "                setattr(self, fieldname, StructField(format, offset))\n",
    "                offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)\n",
    "\n",
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))\n",
    "\n",
    "class Point(Structure):\n",
    "    _fields_ = [\n",
    "        ('<d', 'x'),\n",
    "        ('d', 'y')\n",
    "        ]\n",
    "    \n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        (Point, 'min'), # nested struct\n",
    "        (Point, 'max'), # nested struct\n",
    "        ('i', 'num_polys')\n",
    "        ]\n",
    "\n",
    "f = open('data/poly.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "print(phead.file_code == 0x1234)\n",
    "print(phead.min.x)\n",
    "print(phead.min.y)\n",
    "print(phead.max.x)\n",
    "print(phead.max.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Polygon 0\n(1.0, 2.5)\n(3.5, 4.0)\n(2.5, 1.5)\nPolygon 1\n(7.0, 1.2)\n(5.1, 3.0)\n(0.5, 7.5)\n(0.8, 9.0)\nPolygon 2\n(3.4, 6.3)\n(1.2, 0.5)\n(4.6, 9.2)\n"
    }
   ],
   "source": [
    "class SizedRecord:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, f, size_fmt, includes_size=True):\n",
    "        sz_nbytes = struct.calcsize(size_fmt)\n",
    "        sz_bytes = f.read(sz_nbytes)\n",
    "        sz, = struct.unpack(size_fmt, sz_bytes)\n",
    "        buf = f.read(sz - includes_size * sz_nbytes)\n",
    "        return cls(buf)\n",
    "\n",
    "    def iter_as(self, code):\n",
    "        if isinstance(code, str):\n",
    "            s = struct.Struct(code)\n",
    "            for off in range(0, len(self._buffer), s.size):\n",
    "                yield s.unpack_from(self._buffer, off)\n",
    "        elif isinstance(code, StructureMeta):\n",
    "            size = code.struct_size\n",
    "            for off in range(0, len(self._buffer), size):\n",
    "                data = self._buffer[off:off+size]\n",
    "                yield code(data)\n",
    "\n",
    "f = open('data/poly.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "polydata = [ SizedRecord.from_file(f, '<i') for n in range(phead.num_polys)]\n",
    "for n, poly in enumerate(polydata):\n",
    "    print('Polygon', n)\n",
    "    for p in poly.iter_as('<dd'):\n",
    "        print(p)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594860945196",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}