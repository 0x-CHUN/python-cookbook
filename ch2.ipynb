{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章：字符串和文本 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  使用多个界定符分割字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n"
    }
   ],
   "source": [
    "line = 'asdf fjdk; afed, fjek,asdf, foo'\n",
    "import re\n",
    "print(re.split(r'[;,\\s]\\s*',line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串开头或结尾匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nFalse\n['ch1.ipynb', 'ch2.ipynb']\n"
    }
   ],
   "source": [
    "filename = 'spam.txt'\n",
    "print(filename.endswith('.txt'))\n",
    "print(filename.startswith('file:'))\n",
    "import os\n",
    "filenames = os.listdir('.')\n",
    "print([name for name in filenames if name.endswith('.ipynb')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用 Shell 通配符匹配字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nTrue\n------------------\nTrue\nFalse\n"
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "print(fnmatch('foo.txt','*.txt'))\n",
    "print(fnmatch('foo.txt', '?oo.txt'))\n",
    "print(fnmatch('Dat45.csv', 'Dat[0-9]*'))\n",
    "# fnmatch() 函数使用底层操作系统的大小写敏感规则\n",
    "# 如果对这个区别很在意，可以使用 fnmatchcase() 来代替。它完全使用你的模式大小写匹配。\n",
    "print(\"------------------\")\n",
    "print(fnmatch('foo.txt', '*.TXT'))\n",
    "print(fnmatchcase('foo.txt','*.TXT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串匹配和搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\n10\nyes\nno\nyes\nno\n['11/27/2012', '3/13/2013']\n11 27 2012\n('11', '27', '2012')\n"
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "print(text.startswith('yeah'))\n",
    "print(text.endswith('yeah'))\n",
    "print(text.find('no'))\n",
    "# 复杂的匹配可以使用正则表达式\n",
    "text1 = '11/27/2012'\n",
    "text2 = 'Nov 27, 2012'\n",
    "import re\n",
    "if re.match('\\d+/\\d+/\\d+',text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "if re.match('\\d+/\\d+/\\d+',text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "# 预编译\n",
    "datepat = re.compile('\\d+/\\d+/\\d+')\n",
    "if datepat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "if datepat.match(text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "print(datepat.findall(text))\n",
    "\n",
    "# 在定义正则式的时候，通常会利用括号去捕获分组。\n",
    "datepat = re.compile('(\\d+)/(\\d+)/(\\d+)')\n",
    "m = datepat.match('11/27/2012')\n",
    "print(m.group(1),m.group(2),m.group(3))\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  字符串搜索和替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "yep, but no, but yep, but no, but yep\nToday is 2012-11-27. PyCon starts 2013-3-13.\nToday is 27 Nov 2012. PyCon starts 13 Mar 2013.\nToday is 2012-11-27. PyCon starts 2013-3-13.\n2\n"
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "print(text.replace('yeah','yep'))\n",
    "\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "import re\n",
    "print(re.sub(r'(\\d+)/(\\d+)/(\\d+)',r'\\3-\\1-\\2',text))\n",
    "\n",
    "from calendar import month_abbr\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "print(datepat.sub(change_date, text))\n",
    "\n",
    "newtext, n = datepat.subn(r'\\3-\\1-\\2',text)\n",
    "print(newtext)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串忽略大小写的搜索替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['PYTHON', 'python', 'Python']\nUPPER snake, lower snake, Mixed snake\nUPPER SNAKE, lower snake, Mixed Snake\n"
    }
   ],
   "source": [
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "print(re.findall('python', text, flags=re.IGNORECASE))\n",
    "print(re.sub('python','snake', text, flags=re.IGNORECASE))\n",
    "\n",
    "def matchcase(word):\n",
    "    def replace(m):\n",
    "        text = m.group()\n",
    "        if text.isupper():\n",
    "            return word.upper()\n",
    "        elif text.islower():\n",
    "            return word.lower()\n",
    "        elif text[0].isupper():\n",
    "            return word.capitalize()\n",
    "        else:\n",
    "            return word\n",
    "    return replace\n",
    "print(re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最短匹配模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['no.']\n['no.\" Phone says \"yes.']\n['no.', 'yes.']\n"
    }
   ],
   "source": [
    "# 贪婪模式\n",
    "str_pat = re.compile('\\\"(.*)\\\"')\n",
    "text1 = 'Computer says \"no.\"'\n",
    "print(str_pat.findall(text1))\n",
    "text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "print(str_pat.findall(text2))\n",
    "# 非贪婪模式  \n",
    "str_pat = re.compile(r'\\\"(.*?)\\\"')\n",
    "print(str_pat.findall(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多行匹配模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[' this is a comment ']\n[]\n[' this is a\\nmultiline comment ']\n[' this is a\\nmultiline comment ']\n"
    }
   ],
   "source": [
    "# 无法匹配换行符\n",
    "comment = re.compile('/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "multiline comment */\n",
    "'''\n",
    "print(comment.findall(text1))\n",
    "print(comment.findall(text2))\n",
    "\n",
    "# 增加对换行的支持\n",
    "comment = re.compile('/\\*((?:.|\\n)*?)\\*/')\n",
    "print(comment.findall(text2))\n",
    "\n",
    "# re.DOTALL可以使点 (.) 匹配包括换行符在内的任意字符\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "print(comment.findall(text2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将 Unicode 文本标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Spicy Jalapeño len:14\nSpicy Jalapeño len:15\ns1 == s2 : False\nt1 == t2 : True\nt1 :  Spicy Jalapeño\nt2 :  Spicy Jalapeño\n'Spicy Jalape\\xf1o'\nt3 == t4 : True\nt3 :  Spicy Jalapeño\nt4 :  Spicy Jalapeño\n'Spicy Jalapen\\u0303o'\n"
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "print(s1, 'len:{}'.format(len(s1)))\n",
    "print(s2, 'len:{}'.format(len(s2)))\n",
    "print('s1 == s2 : {}'.format(s1 == s2))\n",
    "\n",
    "import unicodedata\n",
    "# NFC 表示字符应该是整体组成 \n",
    "# 而 NFD 表示字符应该分解为多个组合字符表示。\n",
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "t2 = unicodedata.normalize('NFC', s2)\n",
    "print('t1 == t2 : {}'.format(t1 == t2))\n",
    "print(\"t1 : \", t1)\n",
    "print(\"t2 : \", t2)\n",
    "print(ascii(t1))\n",
    "\n",
    "t3 = unicodedata.normalize('NFD', s1)\n",
    "t4 = unicodedata.normalize('NFD', s2)\n",
    "print('t3 == t4 : {}'.format(t3 == t4))\n",
    "print(\"t3 : \", t3)\n",
    "print(\"t4 : \", t4)\n",
    "print(ascii(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  在正则式中使用 Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "123:\n<re.Match object; span=(0, 3), match='123'>\n١٢٣:\n<re.Match object; span=(0, 3), match='١٢٣'>\n"
    }
   ],
   "source": [
    "import re\n",
    "num = re.compile('\\d+')\n",
    "print('123:')\n",
    "print(num.match('123'))\n",
    "print('\\u0661\\u0662\\u0663:')\n",
    "print(num.match('\\u0661\\u0662\\u0663'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除字符串中不需要的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "'hello world'\n'hello world \\n'\n' hello world'\nhello=====\nhello\n"
    }
   ],
   "source": [
    "s = ' hello world \\n'\n",
    "# strip()去除开始和结尾的字符\n",
    "print(ascii(s.strip()))\n",
    "# lstrip()去除左边的字符\n",
    "print(ascii(s.lstrip()))\n",
    "# rstrip()去除右边的字符\n",
    "print(ascii(s.rstrip()))\n",
    "\n",
    "t = '-----hello====='\n",
    "print(t.lstrip('-'))\n",
    "print(t.strip('-=')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  审查清理文本字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pýtĥöñ\fis\tawesome\n\npýtĥöñ is awesome\n\npýtĥöñ is awesome\n\npython is awesome\n\n"
    }
   ],
   "source": [
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
    "print(s)\n",
    "\n",
    "remap = {\n",
    "    ord('\\t') : ' ',\n",
    "    ord('\\f') : ' ',\n",
    "    ord('\\r') : None\n",
    "}\n",
    "\n",
    "a = s.translate(remap)\n",
    "print(a)\n",
    "\n",
    "import unicodedata, sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) if unicodedata.combining(chr(c)))\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "print(b)\n",
    "print(b.translate(cmb_chrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  字符串对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "方法一：\n'Hello World         '\n'         Hello World'\n'    Hello World     '\n'----Hello World-----'\n方法二：\n'Hello World         '\n'         Hello World'\n'    Hello World     '\n'----Hello World-----'\n方法三：\n'     Hello      World'\n"
    }
   ],
   "source": [
    "text = 'Hello World'\n",
    "print('方法一：')\n",
    "print(ascii(text.ljust(20)))\n",
    "print(ascii(text.rjust(20)))\n",
    "print(ascii(text.center(20)))\n",
    "print(ascii(text.center(20,'-')))\n",
    "print('方法二：')\n",
    "print(ascii(format(text, '<20')))\n",
    "print(ascii(format(text, '>20')))\n",
    "print(ascii(format(text, '^20')))\n",
    "print(ascii(format(text, '-^20')))\n",
    "print('方法三：')\n",
    "print(ascii('{:>10s} {:>10s}'.format('Hello', 'World')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并拼接字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Is Chicago Not Chicago?\nIs,Chicago,Not,Chicago?\n"
    }
   ],
   "source": [
    "# 对于少量的拼接运算使用+即可\n",
    "# join挺方便的\n",
    "parts = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
    "print(' '.join(parts))\n",
    "print(','.join(parts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串中插入变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Guido has 37 messages.\nGuido has 37 messages.\nGuido has 37 messages.\nHello Guido\nYou have 37 messages.\nYour favorite color is {color}\n"
    }
   ],
   "source": [
    "s = '{name} has {n} messages.'\n",
    "print(s.format(name='Guido', n = 37))\n",
    "name = 'Guido'\n",
    "n = 37\n",
    "print(s.format_map(vars()))\n",
    "\n",
    "class Info:\n",
    "    def __init__(self, name, n):\n",
    "        self.name = name\n",
    "        self.n = n\n",
    "\n",
    "a = Info('Guido', 37)\n",
    "print(s.format_map(vars(a)))\n",
    "\n",
    "class safesub(dict):\n",
    "    def __missing__(self, key):\n",
    "        return '{' + key + '}'\n",
    "\n",
    "import sys\n",
    "# sys._getframe(1) 返回调用者的栈帧。可以从中访问属性f_locals 来获得局部变量\n",
    "def sub(text):\n",
    "    return text.format_map(safesub(sys._getframe(1).f_locals))  \n",
    "\n",
    "\n",
    "print(sub('Hello {name}'))\n",
    "print(sub('You have {n} messages.'))\n",
    "print(sub('Your favorite color is {color}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  以指定列宽格式化字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\nnot around the eyes, don't look around the eyes, look into my eyes,\nyou're under.\n----------------------------------------------------------------------\nLook into my eyes, look into my eyes,\nthe eyes, the eyes, the eyes, not around\nthe eyes, don't look around the eyes,\nlook into my eyes, you're under.\n----------------------------------------------------------------------\n  Look into my eyes, look into my eyes,\nthe eyes, the eyes, the eyes, not around\nthe eyes, don't look around the eyes,\nlook into my eyes, you're under.\n----------------------------------------------------------------------\nLook into my eyes, look into my eyes,\n the eyes, the eyes, the eyes, not\n around the eyes, don't look around the\n eyes, look into my eyes, you're under.\n"
    }
   ],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\"\n",
    "import textwrap\n",
    "print(textwrap.fill(s,70))\n",
    "print('-'*70)\n",
    "print(textwrap.fill(s,40))\n",
    "print('-'*70)\n",
    "print(textwrap.fill(s,40, initial_indent='  '))\n",
    "print('-'*70)\n",
    "print(textwrap.fill(s, 40, subsequent_indent=' '))\n",
    "\n",
    "# textwrap 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端大小的时候。你可以使用 os.get_terminal_size() 方法来获取终端的大小尺寸。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在字符串中处理 html 和 xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Elements are written as \"<tag>text</tag>\".\nElements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\nElements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\nb'Spicy Jalape&#241;o'\nSpicy \"Jalapeño\".\nThe prompt is >>>\n"
    }
   ],
   "source": [
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "import html\n",
    "print(s)\n",
    "print(html.escape(s))\n",
    "print(html.escape(s, quote=False))\n",
    "\n",
    "s = 'Spicy Jalapeño'\n",
    "print(s.encode('ascii', errors='xmlcharrefreplace'))\n",
    "\n",
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "from html.parser import HTMLParser\n",
    "p = HTMLParser()\n",
    "print(p.unescape(s))\n",
    "\n",
    "t = 'The prompt is &gt;&gt;&gt;'\n",
    "from xml.sax.saxutils import unescape\n",
    "print(unescape(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  字符串令牌解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Token(type='NAME', value='foo')\nToken(type='WS', value=' ')\nToken(type='EQ', value='=')\nToken(type='WS', value=' ')\nToken(type='NUM', value='42')\n"
    }
   ],
   "source": [
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    from collections import namedtuple\n",
    "    Token = namedtuple('Token', ['type', 'value'])\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "\n",
    "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现一个简单的递归下降分析器\n",
    "\n",
    "```\n",
    "expr ::= expr + term\n",
    "| expr - term\n",
    "| term\n",
    "term ::= term * factor\n",
    "| term / factor\n",
    "| factor\n",
    "factor ::= ( expr )\n",
    "| NUM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2\n5\n14\n37\n"
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
    "DIVIDE, LPAREN, RPAREN, WS]))\n",
    "Token = collections.namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n",
    "\n",
    "class ExpressionEvaluator:\n",
    "    def parse(self, text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None # Last symbol consumed\n",
    "        self.nexttok = None # Next symbol tokenized\n",
    "        self._advance() # Load first lookahead token\n",
    "        return self.expr()\n",
    "\n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "        \n",
    "    def _accept(self, toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def _expect(self, toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "    \n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | ( expr )\"\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "            \n",
    "def descent_parser():\n",
    "    e = ExpressionEvaluator()\n",
    "    print(e.parse('2'))\n",
    "    print(e.parse('2 + 3'))\n",
    "    print(e.parse('2 + 3 * 4'))\n",
    "    print(e.parse('2 + (3 + 4) * 5'))\n",
    "\n",
    "descent_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字节字符串上的字符串操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "b'Hello'\nTrue\n[b'Hello', b'World']\nb'Hello Cruel World'\nbytearray(b'Hello')\nTrue\n[bytearray(b'Hello'), bytearray(b'World')]\nbytearray(b'Hello Cruel World')\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[b'FOO', b'BAR', b'SPAM']"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "# 字节字符串\n",
    "data = b'Hello World'\n",
    "print(data[0:5])\n",
    "print(data.startswith(b'Hello'))\n",
    "print(data.split())\n",
    "print(data.replace(b'Hello', b'Hello Cruel'))\n",
    "# 字节数组\n",
    "data = bytearray(b'Hello World')\n",
    "print(data[0:5])\n",
    "print(data.startswith(b'Hello'))\n",
    "print(data.split())\n",
    "print(data.replace(b'Hello', b'Hello Cruel'))\n",
    "\n",
    "data = b'FOO:BAR,SPAM'\n",
    "import re\n",
    "re.split(b'[:,]',data) # Notice: pattern as bytes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}